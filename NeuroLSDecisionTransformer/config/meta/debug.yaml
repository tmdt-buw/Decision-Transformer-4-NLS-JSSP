# @package _global_

# tensorboard --host localhost --port 8080 --logdir=./outputs

run_type: "debug"
debug_lvl: 1  # 0 disables debugging and verbosity completely, >1 activates additional debugging functionality
global_seed: 1234
cuda: True

# global paths and logging
log_lvl: INFO
tb_log_path: 'logs/tb/'
val_log_path: 'logs/val/'
test_log_path: 'logs/test/'
checkpoint_save_path: 'checkpoints/'
checkpoint_load_path: #


# global training args
train_batch_size: 8 #32      # number of training envs
update_batch_size: 32 #256    # size of mini batch for model parameter updates
val_dataset_size: 16 #32 #512
val_batch_size: 8 #8 #32       # number of val envs


env_kwargs:
  report_on_improvement: False

replay_buffer_cfg:
  total_size: 10000 #32000

eval_metric_key: 'rew'
render_val: False      # requires val_batch_size = 1

checkpoint_cfg:
  compare_mode: 'max'   # comparison mode of eval metric (rew -> max, cost -> min)
  top_k: 2      # always keep top_k best model checkpoints
  save_last: True   # always safe last model checkpoint


monitor_cfg:
  train_interval: 1000   # log training results every train_interval steps
  update_interval: 2000  # log update results every update_interval steps
  test_interval: 1       # log test results every test_interval epochs
  save_interval: 1       # save checkpoint every save_interval epochs if val metric is better


trainer_cfg:
  max_epoch: 3              # the maximum number of epochs for training
  step_per_epoch: 64 #8192      # the number of transitions collected per epoch.
  step_per_collect: 32 #128     # the number of transitions the collector would collect before the network update

#
tester_cfg:
  test_dataset_size: 128
  test_batch_size: 1
  render: True
  num_render_eps: 1
  test_env_kwargs:
    num_steps: 128    # can only render max ~150 steps as GIF

